{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Minh Canh - s1920426\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nonterminal symbol\n",
    "\"\"\"\n",
    "class Nonterminal():\n",
    "    def __init__(self, symbol):\n",
    "        self._symbol = symbol\n",
    "        self._hash = hash(symbol)\n",
    "\n",
    "    def symbol(self):\n",
    "        return self._symbol\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return type(self) == type(other) and self._symbol == other._symbol\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%s\" % self._symbol\n",
    "    \n",
    "def is_terminal(item):\n",
    "    return not isinstance(item, Nonterminal)\n",
    "\n",
    "def is_nonterminal(item):\n",
    "    return isinstance(item, Nonterminal)\n",
    "\n",
    "\"\"\"\n",
    "Production or Rule\n",
    "- lhs is a nonterminal symbol\n",
    "- rhs is a tuple\n",
    "\"\"\"\n",
    "class Production():\n",
    "    def __init__(self, lhs, rhs):\n",
    "        self._lhs = lhs\n",
    "        self._rhs = tuple(rhs)\n",
    "        assert is_nonterminal(lhs), 'Left hand side must be a nonterminal'\n",
    "        self._hash = hash((self._lhs, self._rhs))\n",
    "    \n",
    "    def lhs(self):\n",
    "        return self._lhs\n",
    "    \n",
    "    def rhs(self):\n",
    "        return self._rhs\n",
    "    \n",
    "    def is_nonlexical(self):\n",
    "        \"\"\"\n",
    "        Return True if the righ-hand contains only nonterminal token.\n",
    "        \"\"\"\n",
    "        return all(is_nonterminal(n) for n in self._rhs)\n",
    "    \n",
    "    def is_lexical(self):\n",
    "        \"\"\"\n",
    "        return True if the right-hand side contains at least on terminal token\n",
    "        \"\"\"\n",
    "        return not self.is_nonlexical()\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            type(self) == type(other) and\n",
    "            self._lhs == other._lhs and\n",
    "            self._rhs == other._rhs\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        result = \"%s -> \" % repr(self._lhs)\n",
    "        result += \" \".join(repr(el) for el in self._rhs)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal_text(item):\n",
    "    return re.search('^[A-Z]', item) is None\n",
    "\n",
    "def is_nonterminal_text(item):\n",
    "    return not re.search('^[A-Z]', item) is None\n",
    "\n",
    "\"\"\"\n",
    "Context Free Grammar - CFG\n",
    "- read FFG from a list of strings that presents for rules\n",
    "\"\"\"\n",
    "class CFG():\n",
    "    def __init__(self, lines):\n",
    "        self._rules = set()\n",
    "        self._start = None\n",
    "        for idx, line in enumerate(lines):\n",
    "            tokens = line.split()\n",
    "            assert len(tokens) > 1, '% is invalid' % line\n",
    "            assert is_nonterminal_text(tokens[0]), 'lhs must be a nonterminal'\n",
    "            lhs = Nonterminal(tokens[0])\n",
    "            rhs = []\n",
    "            if idx == 0: self._start = lhs\n",
    "            for token in tokens[1:]:\n",
    "                if is_nonterminal_text(token):\n",
    "                    rhs.append(Nonterminal(token))\n",
    "                else:\n",
    "                    rhs.append(token)\n",
    "\n",
    "            if all(is_terminal(n) for n in rhs):\n",
    "                # if the lhs contains only terminal tokens, we should make it separated\n",
    "                for token in rhs:\n",
    "                    self._rules.add(Production(lhs, token))\n",
    "            else:\n",
    "                self._rules.add(Production(lhs, rhs))\n",
    "    \n",
    "    def start(self):\n",
    "        return self._start\n",
    "    \n",
    "    def rules(self):\n",
    "        return self._rules\n",
    "    \n",
    "    def addRule(self, rule):\n",
    "        self._rules.add(rule)\n",
    "        \n",
    "    def getNonLexicalRule(self):\n",
    "        for rule in self._rules:\n",
    "            if rule.is_nonlexical() and len(rule.rhs()) > 2:\n",
    "                return rule\n",
    "        return None\n",
    "    \n",
    "    def findRule(self, rhs):\n",
    "        # find rule with exactly same rhs\n",
    "        rules = set()\n",
    "        for rule in self.rules():\n",
    "            if rule.rhs() == tuple(rhs):\n",
    "                rules.add(rule)\n",
    "        return rules\n",
    "    \n",
    "    def findRuleIn(self, eleSet):\n",
    "        # find rule such that lhs is not in eleSet and \n",
    "        # rhs intersects with eleSet that is not empty\n",
    "        rules = set()\n",
    "        for rule in self.rules():\n",
    "            if (rule.lhs() not in eleSet) and len(set(rule.rhs()) & eleSet) > 0:\n",
    "                rules.add(rule)\n",
    "        return rules\n",
    "    \n",
    "    def toFile(self, path):\n",
    "        f = open(path, \"w\")\n",
    "        for rule in self.rules():\n",
    "            f.write(\"%s\\t%s\\n\" % (rule.lhs().symbol(), \"\\t\".join(repr(el) for el in rule.rhs())))\n",
    "        f.close()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        result = \"Start symbol is %s\\n\" % repr(self._start)\n",
    "        result += \"\\n\".join(repr(rule) for rule in self._rules)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Used to build a combination from choices\n",
    "\"\"\"\n",
    "class Combination():\n",
    "    def __init__(self, choices):\n",
    "        self.solutions = []\n",
    "        self.visited = [0] * len(choices)\n",
    "        self.choices = choices\n",
    "        \n",
    "    def build(self):\n",
    "        if len(self.solutions) == 0:\n",
    "            self.backtrack(0)\n",
    "        return self.solutions\n",
    "    \n",
    "    def addSolution(self):\n",
    "        solution = []\n",
    "        for idx, x in enumerate(self.choices):\n",
    "            if (self.visited[idx] == 1):\n",
    "                solution.append(x)\n",
    "        self.solutions.append(solution)\n",
    "        \n",
    "    def backtrack(self, i):\n",
    "        if (i >= len(self.choices)):\n",
    "            self.addSolution()\n",
    "            return\n",
    "        self.visited[i] = 0\n",
    "        self.backtrack(i + 1)\n",
    "        self.visited[i] = 1\n",
    "        self.backtrack(i + 1)\n",
    "        \n",
    "\"\"\"\n",
    "Chomsky Normal Form (CNF) - extends from CFG\n",
    "- Reading from a list of strings that presents rules. Then such rules are converted to CNF\n",
    "\"\"\"\n",
    "class CNF(CFG):\n",
    "    \n",
    "    def __init__(self, lines, convertCNF=True):\n",
    "        super().__init__(lines)\n",
    "        if convertCNF:\n",
    "            self.convertToCNF()\n",
    "            \n",
    "    def convertToCNF(self):\n",
    "        self.eliminateStart()\n",
    "        self.simplifyCFG()\n",
    "        self.removeMixedRules()\n",
    "        self.makeRulesBinary()\n",
    "    \n",
    "    def eliminateStart(self):\n",
    "        start = self.start()\n",
    "        need_to_add = None\n",
    "        for rule in self.rules():\n",
    "            if start in rule.rhs():\n",
    "                need_to_add = True\n",
    "                break\n",
    "        if need_to_add:\n",
    "            self._start = Nonterminal('S*')\n",
    "            self.addRule(Production(self.start(), [start]))\n",
    "            \n",
    "    def simplifyCFG(self):\n",
    "        self.removeUselessProduction()\n",
    "        self.removeNullProduction()\n",
    "        self.removeUnitProductions()\n",
    "        \n",
    "    def removeUselessProduction(self):\n",
    "        uselessRules = set()\n",
    "        start = self.start()\n",
    "        for rule in self.rules():\n",
    "            if rule.lhs() == start:\n",
    "                continue\n",
    "            used = any([rule.lhs() in r.rhs() for r in self.rules() if r != rule])\n",
    "            if not used:\n",
    "                uselessRules.add(rule)\n",
    "        self._rules = self.rules() - uselessRules\n",
    "    \n",
    "    def removeNullProduction(self):\n",
    "        # assuming that 'λ' is used the nul production\n",
    "        # finding nul variables set\n",
    "        nulVarSet = set(['λ'])\n",
    "        while True:\n",
    "            rules = self.findRuleIn(nulVarSet)\n",
    "            if len(rules) == 0:\n",
    "                break\n",
    "            nulVarSet = nulVarSet | {rule.lhs() for rule in rules}\n",
    "        nulVarSet = nulVarSet  - set(['λ', self.start()])\n",
    "        \n",
    "        # make new rules with null variables set by combination\n",
    "        rules = set()\n",
    "        for rule in self.rules():\n",
    "            if len(rule.rhs()) == 1 and rule.rhs()[0] == 'λ':\n",
    "                continue\n",
    "            inter = set(rule.rhs()) & nulVarSet\n",
    "            if len(inter) == 0:\n",
    "                rules.add(rule)\n",
    "            if len(inter) > 0:\n",
    "                rhs = rule.rhs()\n",
    "                # get combination of intersected elements\n",
    "                cbi = Combination(list(inter)).build()\n",
    "                # create a new rule for each combination\n",
    "                for sol in cbi:\n",
    "                    new_rhs = []\n",
    "                    for ele in rhs:\n",
    "                        if ele not in sol:\n",
    "                            new_rhs.append(ele)\n",
    "                    if len(new_rhs) > 0:\n",
    "                        rules.add(Production(rule.lhs(), new_rhs))\n",
    "        self._rules = rules\n",
    "    \n",
    "    def removeUnitProductions(self):\n",
    "        rules = {rule for rule in self.rules() if \\\n",
    "                 len(rule.rhs()) > 1 or \\\n",
    "                 (len(rule.rhs()) == 1 and is_terminal(rule.rhs()[0])) \\\n",
    "                 }\n",
    "        unit_rules = self.rules() - rules\n",
    "        \n",
    "        for unit_rule in unit_rules:\n",
    "            values = set()\n",
    "            single_variable = unit_rule.rhs()[0]\n",
    "            for rule in rules:\n",
    "                if rule.lhs() == single_variable:\n",
    "                    values.add(rule.rhs())\n",
    "            \n",
    "            for val in values:\n",
    "                rules.add(Production(unit_rule.lhs(), val))\n",
    "        self._rules = rules\n",
    "        self.removeUselessProduction()\n",
    "        \n",
    "    def removeMixedRules(self, padding='_'):\n",
    "        # finding lexical rules\n",
    "        lexical_rules = {rule for rule in self.rules() if rule.is_lexical() and len(rule.rhs()) > 1}\n",
    "        add_rules = set()\n",
    "        for lexical_rule in lexical_rules:\n",
    "            rhs = []\n",
    "            for token in lexical_rule.rhs():\n",
    "                if is_terminal(token):\n",
    "                    new_token = Nonterminal(token + padding)\n",
    "                    add_rules.add(Production(new_token, token))\n",
    "                    rhs.append(new_token)\n",
    "                else:\n",
    "                    rhs.append(token)\n",
    "            add_rules.add(Production(lexical_rule.lhs(), rhs))\n",
    "        self._rules = (self.rules() - lexical_rules) | add_rules\n",
    "    \n",
    "    def makeRulesBinary(self, padding='&'):\n",
    "        while True:\n",
    "            rule = self.getNonLexicalRule()\n",
    "            if rule is None:\n",
    "                break;\n",
    "            \n",
    "            lhs = rule.lhs()\n",
    "            rhs = list(rule.rhs())\n",
    "            head = rhs[:2]\n",
    "            remainder = rhs[2:] \n",
    "            \n",
    "            new_token = Nonterminal(head[0].symbol() + padding + head[1].symbol())\n",
    "            self._rules.add(Production(lhs, [new_token] + remainder))\n",
    "            self._rules.add(Production(new_token, head))\n",
    "            self._rules.remove(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Each cell data structure in the CKY table\n",
    "\"\"\"\n",
    "class CKY_Cell():\n",
    "    def __init__(self, i, j):\n",
    "        self._solutions = []\n",
    "        self._position = (i, j)\n",
    "\n",
    "    def addSolution(self, rule, left=None, right=None, idxLeft=None, idxRight=None):\n",
    "        self._solutions.append((rule, left, right, idxLeft, idxRight))\n",
    "    \n",
    "    def solutions(self):\n",
    "        return self._solutions\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if len(self._solutions) == 0:\n",
    "            return '∅'\n",
    "        else:\n",
    "            results = []\n",
    "            for (rule, left, right, idxLeft, idxRight) in self._solutions:\n",
    "                if not isinstance(left, CKY_Cell) or not isinstance(right, CKY_Cell):\n",
    "                    results.append(rule.lhs().symbol())\n",
    "                else:\n",
    "                    results.append('%s { %s , %s }' % (rule.lhs().symbol(),\\\n",
    "                                                  left.solutions()[idxLeft][0].lhs().symbol(),\\\n",
    "                                                 right.solutions()[idxRight][0].lhs().symbol()))\n",
    "                \n",
    "            return \"\\n\".join(results)\n",
    "\n",
    "\"\"\"\n",
    "CKY algorithm given an grammar in the form of CNF\n",
    "\"\"\"\n",
    "class CKY():\n",
    "    def __init__(self, grammar):\n",
    "        self._grammar = grammar\n",
    "    \n",
    "    \"\"\"\n",
    "    Parse a sentence and return (tokens, matrix)\n",
    "    - tokens is built from the sentence\n",
    "    - matrix is behalf on the CKY table\n",
    "    \"\"\"\n",
    "    def parse(self, sentence):\n",
    "        grammar = self.grammar()\n",
    "        tokens = [c for c in sentence if c != ' ']\n",
    "        N = len(tokens)\n",
    "        M = np.empty((N, N), dtype=object)\n",
    "        # initialization\n",
    "        for i in range(N):\n",
    "            cell = CKY_Cell(i, i)\n",
    "            rules = grammar.findRule([tokens[i]])\n",
    "            assert len(rules) > 0, 'Data is invalid'\n",
    "            for rule in rules:\n",
    "                if rule.lhs() != grammar.start():\n",
    "                    cell.addSolution(rule)\n",
    "            M[i][i] = cell\n",
    "\n",
    "        # start building CKY table\n",
    "        for d in range(1, N):\n",
    "            for i in range(N - d):\n",
    "                j = i + d\n",
    "                cell = CKY_Cell(i, j)\n",
    "                for k in range(i, j):\n",
    "                    if not isinstance(M[i][k], CKY_Cell) or not isinstance(M[k+1][j], CKY_Cell):\n",
    "                        continue\n",
    "                    leftSolutions = M[i][k].solutions()\n",
    "                    rightSolutions = M[k+1][j].solutions()\n",
    "                    for idxLeft, (leftRule, *restLef) in enumerate(leftSolutions):\n",
    "                        for idxRight, (rightRule, *restRight) in enumerate(rightSolutions):\n",
    "                            rules = grammar.findRule([leftRule.lhs(), rightRule.lhs()])\n",
    "                            for rule in rules:\n",
    "                                if rule.lhs() != grammar.start() or (i == 0 and j == N-1):\n",
    "                                    cell.addSolution(rule, M[i][k], M[k+1][j], idxLeft, idxRight)\n",
    "                # if len(cell.solutions()) > 0:\n",
    "                M[i][j] = cell\n",
    "        count = 0\n",
    "        if isinstance(M[0][N-1], CKY_Cell):\n",
    "            for rule, *rest in M[0][N-1].solutions():\n",
    "                if rule.lhs() == grammar.start():\n",
    "                    count += 1\n",
    "                    \n",
    "        if count == 0:\n",
    "            print(\"Cannot parse %s\" % sentence)\n",
    "        else:\n",
    "            print('Parse sucessfully. Number of parse tree is %d' % count)\n",
    "        return tokens, M\n",
    "    \n",
    "    def grammar(self):\n",
    "        return self._grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Drawing a table given a name of output file, columns and matrix values\n",
    "Output is an image file\n",
    "\"\"\"\n",
    "def draw_table(fileName, columns, values):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_axis_off()\n",
    "    ytable = ax.table(cellText=values,\n",
    "                      colLabels=columns, \n",
    "                      colColours =[\"palegreen\"]*len(columns),\n",
    "                      cellLoc='center', \n",
    "                      loc='upper left', colWidths=[1]*len(columns))\n",
    "    ytable.set_fontsize(20)\n",
    "    ytable.scale(1, 10)\n",
    "    cellDict = ytable.get_celld()\n",
    "    for i in range(0, len(columns)):\n",
    "        cellDict[(0, i)].set_text_props(color='b', fontweight='bold')\n",
    "    plt.savefig(fileName, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Synthesizing what need to do in mini project 3\n",
    "Input:\n",
    "    - input/cfg_rule.txt file\n",
    "    - input/sentence.txt file\n",
    "Ouput:\n",
    "    - output/cnf_rule.txt\n",
    "    - output/CKY_Table.png\n",
    "    - output/Filled_CKY_Table.png\n",
    "\"\"\"\n",
    "def project3():\n",
    "    # reading cfg from file\n",
    "    cfg_file = open('input/cfg_rule.txt', 'r')\n",
    "    cfg_lines = cfg_file.readlines()\n",
    "    # reading the sentence from file\n",
    "    sentence_file = open('input/sentence.txt', 'r')\n",
    "    sentence = sentence_file.readline()\n",
    "    # building CNF grammar\n",
    "    cnf = CNF(cfg_lines)\n",
    "    # save CNF grammar to file\n",
    "    cnf.toFile(\"output/cnf_rule.txt\")\n",
    "    # using CKY with the CNF grammar\n",
    "    cky = CKY(cnf)\n",
    "    # parsing a sentense\n",
    "    columns, matrix = cky.parse(sentence)\n",
    "    # draw CKY table for the sentence\n",
    "    draw_table('output/CKY_Table.png', columns, np.empty((len(columns), len(columns)), dtype=object))\n",
    "    # draw CKY table with filled values by the CKY algorithm\n",
    "    draw_table('output/Filled_CKY_Table.png', columns, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse sucessfully. Number of parse tree is 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's see the result in the `output` folder\n",
    "\"\"\"\n",
    "project3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
